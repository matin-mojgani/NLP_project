{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bb0e5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment Ready.\n",
      "üìÇ Project Root: c:\\Users\\matin\\Desktop\\uni\\nlp\\project\\rumor-detection-elkp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import spacy\n",
    "import wikipediaapi\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- 1. Environment Setup ---\n",
    "# Dynamically find the project root (one level up from 'demo' folder)\n",
    "current_dir = os.getcwd()\n",
    "project_root = os.path.dirname(current_dir)\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(os.path.join(project_root, '.env'))\n",
    "\n",
    "# Define Paths\n",
    "MODEL_PATH = os.path.join(project_root, \"models\", \"rumor_model\")\n",
    "TEST_DATA_PATH = os.path.join(project_root, \"data\", \"processed\", \"test_dataset.csv\")\n",
    "\n",
    "print(f\"‚úÖ Environment Ready.\\nüìÇ Project Root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7558f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading Model on CPU...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1a204db42c421b94a5492f3d9fabfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Loading Knowledge Base (SpaCy & Wiki)...\n",
      "‚úÖ Detector Initialized Successfully.\n"
     ]
    }
   ],
   "source": [
    "class RumorDetector:\n",
    "    \"\"\"\n",
    "    Wraps the ELKP pipeline: Knowledge Injection + BERT Inference.\n",
    "    \"\"\"\n",
    "    \n",
    "    LABEL_MAP = {0: \"NON-RUMOR (Real)\", 1: \"RUMOR (Fake)\"}\n",
    "    \n",
    "    def __init__(self, model_path):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"‚è≥ Loading Model on {self.device.upper()}...\")\n",
    "        \n",
    "        # 1. Load AI Model\n",
    "        try:\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "            self.model.to(self.device)\n",
    "            self.model.eval() # Set to evaluation mode\n",
    "        except OSError:\n",
    "            raise FileNotFoundError(f\"‚ùå Model not found at {model_path}. Did you train it?\")\n",
    "\n",
    "        # 2. Load Knowledge Tools\n",
    "        print(\"‚è≥ Loading Knowledge Base (SpaCy & Wiki)...\")\n",
    "        try:\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "        except OSError:\n",
    "            os.system(\"python -m spacy download en_core_web_sm\")\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "            \n",
    "        self.wiki = wikipediaapi.Wikipedia(\n",
    "            language='en', \n",
    "            user_agent='RumorDemo/1.0 (student@uni.edu)'\n",
    "        )\n",
    "        print(\"‚úÖ Detector Initialized Successfully.\")\n",
    "\n",
    "    def predict(self, text: str) -> dict:\n",
    "        \"\"\"\n",
    "        Full pipeline: Text -> Entity -> Wiki -> Knowledge Prompt -> BERT -> Result\n",
    "        \"\"\"\n",
    "        # Step A: Knowledge Injection\n",
    "        knowledge = self._fetch_knowledge(text)\n",
    "        \n",
    "        if knowledge:\n",
    "            prompt = f\"Knowledge: {knowledge} [SEP] Tweet: {text}\"\n",
    "        else:\n",
    "            prompt = f\"Tweet: {text}\"\n",
    "\n",
    "        # Step B: Model Inference\n",
    "        inputs = self.tokenizer(\n",
    "            prompt, \n",
    "            return_tensors=\"pt\", \n",
    "            truncation=True, \n",
    "            max_length=128\n",
    "        ).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "            pred_idx = torch.argmax(probs).item()\n",
    "            confidence = probs[0][pred_idx].item()\n",
    "\n",
    "        return {\n",
    "            \"original_text\": text,\n",
    "            \"knowledge_found\": knowledge,\n",
    "            \"prediction_label\": self.LABEL_MAP[pred_idx],\n",
    "            \"prediction_code\": pred_idx,\n",
    "            \"confidence\": confidence\n",
    "        }\n",
    "\n",
    "    def _fetch_knowledge(self, text):\n",
    "        \"\"\"Helper to extract entity and query Wikipedia.\"\"\"\n",
    "        doc = self.nlp(text)\n",
    "        if not doc.ents:\n",
    "            return None\n",
    "        \n",
    "        # Taking the first major entity\n",
    "        entity = doc.ents[0].text\n",
    "        try:\n",
    "            page = self.wiki.page(entity)\n",
    "            if page.exists():\n",
    "                return f\"Entity: {entity} | Info: {page.summary[:200]}...\"\n",
    "        except:\n",
    "            return None\n",
    "        return None\n",
    "\n",
    "# Instantiate the engine once\n",
    "detector = RumorDetector(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "775a9606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_result(result: dict, true_label: int = None):\n",
    "    \"\"\"Prints the prediction results in a clean, human-readable format.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"üìù INPUT TWEET:\\n\\\"{result['original_text']}\\\"\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Show Knowledge\n",
    "    if result['knowledge_found']:\n",
    "        print(f\"üß† KNOWLEDGE INJECTED:\\n   {result['knowledge_found']}\")\n",
    "    else:\n",
    "        print(\"‚ö™ No external knowledge found (Pure text analysis).\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Show Prediction\n",
    "    print(f\"ü§ñ AI PREDICTION:  {result['prediction_label']}\")\n",
    "    print(f\"üìä CONFIDENCE:     {result['confidence']:.2%}\")\n",
    "    \n",
    "    # Verification (if we know the truth)\n",
    "    if true_label is not None:\n",
    "        truth_str = detector.LABEL_MAP[true_label]\n",
    "        is_correct = (result['prediction_code'] == true_label)\n",
    "        icon = \"‚úÖ CORRECT\" if is_correct else \"‚ùå INCORRECT\"\n",
    "        print(f\"üéØ ACTUAL LABEL:   {truth_str} -> {icon}\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83ae987d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìù INPUT TWEET:\n",
      "\"Tweet: \"At least 1 gunman\" in #SydneySiege (image of suspect not verified) No injuries known - police http://t.co/XLklHFHCT3 http://t.co/Rxh3RH2RMS\"\n",
      "------------------------------------------------------------\n",
      "‚ö™ No external knowledge found (Pure text analysis).\n",
      "------------------------------------------------------------\n",
      "ü§ñ AI PREDICTION:  RUMOR (Fake)\n",
      "üìä CONFIDENCE:     98.77%\n",
      "üéØ ACTUAL LABEL:   RUMOR (Fake) -> ‚úÖ CORRECT\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the unseen test dataset\n",
    "if os.path.exists(TEST_DATA_PATH):\n",
    "    test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "    \n",
    "    # Pick 1 random sample\n",
    "    sample = test_df.sample(1).iloc[0]\n",
    "\n",
    "\n",
    "    raw_text = sample['text']\n",
    "    if \"[SEP] Tweet:\" in raw_text:\n",
    "        raw_text = raw_text.split(\"[SEP] Tweet:\")[-1].strip()\n",
    "\n",
    "\n",
    "    # Run the Pipeline\n",
    "    result = detector.predict(raw_text)\n",
    "    \n",
    "    # Visualize\n",
    "    visualize_result(result, true_label=sample['label'])\n",
    "else:\n",
    "    print(\"‚ùå Test data not found. Please run main.py first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b40b8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìù INPUT TWEET:\n",
      "\"The PM's office releases a statement about  #sydneysiege. http://t.co/7NdqPYhwcY http://t.co/jeYdlwywO7\"\n",
      "------------------------------------------------------------\n",
      "üß† KNOWLEDGE INJECTED:\n",
      "   Entity: about  # | Info: About may refer to:\n",
      "\n",
      "About (surname)\n",
      "About.com, an online source for original information and advice\n",
      "about.me, a personal web hosting service\n",
      "About URI scheme, an internal URI scheme\n",
      "About box, a dial...\n",
      "------------------------------------------------------------\n",
      "ü§ñ AI PREDICTION:  NON-RUMOR (Real)\n",
      "üìä CONFIDENCE:     98.44%\n",
      "üéØ ACTUAL LABEL:   RUMOR (Fake) -> ‚ùå INCORRECT\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the unseen test dataset\n",
    "if os.path.exists(TEST_DATA_PATH):\n",
    "    test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "    \n",
    "    # Pick 1 random sample\n",
    "    sample = test_df.sample(1).iloc[0]\n",
    "\n",
    "\n",
    "    raw_text = sample['text']\n",
    "    if \"[SEP] Tweet:\" in raw_text:\n",
    "        raw_text = raw_text.split(\"[SEP] Tweet:\")[-1].strip()\n",
    "\n",
    "\n",
    "    # Run the Pipeline\n",
    "    result = detector.predict(raw_text)\n",
    "    \n",
    "    # Visualize\n",
    "    visualize_result(result, true_label=sample['label'])\n",
    "else:\n",
    "    print(\"‚ùå Test data not found. Please run main.py first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e7fa103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìù INPUT TWEET:\n",
      "\"Breaking: The Eiffel Tower has been sold to a private company.\"\n",
      "------------------------------------------------------------\n",
      "üß† KNOWLEDGE INJECTED:\n",
      "   Entity: The Eiffel Tower | Info: The Eiffel Tower (  EYE-f…ôl; French: Tour Eiffel [tu Å …õf…õl] ) is a lattice tower on the Champ de Mars in Paris, France. It is named after the engineer Gustave Eiffel, whose company designed and built ...\n",
      "------------------------------------------------------------\n",
      "ü§ñ AI PREDICTION:  RUMOR (Fake)\n",
      "üìä CONFIDENCE:     99.85%\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example: A made-up rumor or real news\n",
    "custom_text = \"Breaking: The Eiffel Tower has been sold to a private company.\"\n",
    "\n",
    "# Run Prediction\n",
    "result = detector.predict(custom_text)\n",
    "visualize_result(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
